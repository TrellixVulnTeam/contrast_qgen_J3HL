{
    "model_name_or_path": "pretrained_gpt2/117M",
    "seed": 42,
    "max_seq_length": 2560,
    "skip_eval": false,
    "init_checkpoint": "tuned_gpt2_model/tuned_generator_block.pkl",
    "train_input_file": "data/train.db",
    "eval_input_file": "data/dev.tsv",
    "continue_from": 0,
    "train_batch_size": 8,
    "gradient_accumulation_steps": 8,
    "eval_batch_size": 1,
    "learning_rate": 1e-05,
    "num_optim_steps": 1000000,
    "valid_step": 1000,
    "warmup_proportion": 0.1,
    "warmup_steps": 16000,
    "normalize_data": true,
    "fp16": false,
    "lr_schedule": "noam",
    "loss_scale": 0,
    "no_token_id": true,
    "output_dir": "outputs/models",
    "log_dir": "outputs/l",
    "save_step": 1000,
    "nsamples": 5,
    "batch_size": 1,
    "length": -1,
    "generation_length": 15,
    "temperature": 1,
    "top_k": 0,
    "unconditional": false,
    "is_sampling": true,
    "local_rank": -1,
    "pbar": true,
    "ranker_model": "bert_ranker/marco_ranking/",
    "dist-url": "tcp://127.0.0.1:FREEPORT",
    "dist-backend": "nccl",
    "multiprocessing-distributed": true,
    "world-size": 1,
    "rank": 0,
    "coord_config": "coordinator/coord_config.json",
    "reward_type": "map",
    "use_contrastive_reward": false,
    "initializer_range": 0.02,
    "layer_norm_epsilon": 1e-5,
    "n_ctx": 20,
    "n_embd": 768,
    "n_head": 4,
    "n_layer": 2,
    "n_clusters": 2,
    "vocab_size": 50527,
    "use_baseline_6": true,
    "coord_type": "contrast_attention",
    "rl_wt": 1.0,
    "sl_wt": 100.0,
    "ent_wt": 0.1,
    "use_contrast_damp": true,
    "optimize_option": "all",
    "eval_range_begin": -1,
    "eval_range_end": -1
}