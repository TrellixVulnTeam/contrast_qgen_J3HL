{
    "model_name_or_path": "pretrained_gpt2/117M",
    "seed": 42,
    "max_seq_length": 512,
    "skip_eval": false,
    "init_checkpoint": "pretrained_gpt2/117M/pytorch_model.bin",
    "train_input_file": "data/marco_formatted_train_512.db",
    "eval_input_file": "data/marco_formatted_dev_10k.tsv",
    "continue_from": 0,
    "train_batch_size": 32,
    "gradient_accumulation_steps": 2,
    "eval_batch_size": 16,
    "learning_rate": 1e-05,
    "num_optim_steps": 1000000,
    "valid_step": 500,
    "warmup_proportion": 0.1,
    "warmup_steps": 16000,
    "normalize_data": true,
    "fp16": false,
    "lr_schedule": "noam",
    "loss_scale": 0,
    "no_token_id": true,
    "output_dir": "outputs/models",
    "log_dir": "outputs/l",
    "save_step": 500,
    "nsamples": 5,
    "batch_size": 16,
    "length": -1,
    "generation_length": 20,
    "temperature": 1,
    "top_k": 0,
    "unconditional": false,
    "is_sampling": false,
    "local_rank": -1,
    "pbar": true
}
